name: pyspark-cluster

services:
  spark-master:
    container_name: pyspark-master
    build: .
    image: pyspark-image
    entrypoint: ['./entrypoint.sh', 'master']
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8080" ]
      interval: 5s
      timeout: 3s
      retries: 3
    volumes:
      - ./dados:/opt/spark/data
      - ./jobs:/opt/spark/apps
      - spark-logs:/opt/spark/spark-events
    env_file:
      - .env.spark
    ports:
      - '9091:8080'
      - '7071:7077'

  spark-history-server:
    container_name: pyspark-history
    image: pyspark-image
    entrypoint: ['./entrypoint.sh', 'history']
    depends_on:
      - spark-master
    env_file:
      - .env.spark
    volumes:
      - spark-logs:/opt/spark/spark-events
    ports:
      - '18081:18080'

  spark-worker:
    image: pyspark-image
    entrypoint: ['./entrypoint.sh', 'worker']
    depends_on:
      - spark-master
    env_file:
      - .env.spark
    volumes:
      - ./dados:/opt/spark/data
      - ./jobs:/opt/spark/apps
      - spark-logs:/opt/spark/spark-events
  
  minio:
    image: minio/minio
    container_name: minio
    environment:
      MINIO_REGION_NAME: us-east-1
      MINIO_REGION: us-east-1
      MINIO_DOMAIN: minio
      MINIO_ACCESS_KEY: datalake
      MINIO_SECRET_KEY: datalake
      MINIO_ROOT_USER: admin
      MINIO_ROOT_PASSWORD: datalake
    ports:
      - "9000:9000"
      - "9001:9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
    entrypoint: >
      /bin/sh -c "
      minio server /data --console-address ':9001' &
      sleep 5;
      mc alias set datalake http://localhost:9000 admin datalake;
      mc mb datalake/datalake;
      tail -f /dev/null"

volumes:
  spark-logs: